import pandas as pd
import json
from datetime import datetime
from crawler import get_today_posts
from gemini_sentiment import batch_sentiment_analysis
from keywords import extract_top_keywords
import os

def main(file_path="kospi200.csv", max_stocks=None):
    kospi_df = pd.read_csv(file_path, dtype={"ì¢…ëª©ì½”ë“œ": str})
    if max_stocks:
        kospi_df = kospi_df.head(max_stocks)

    results = []
    today_str = datetime.today().strftime('%Y%m%d')

    for _, row in kospi_df.iterrows():
        code = row['ì¢…ëª©ì½”ë“œ']
        name = row['ì¢…ëª©ëª…']
        print(f"\nğŸ” [{code} | {name}] ê²Œì‹œê¸€ ìˆ˜ì§‘ ì¤‘...")

        df = get_today_posts(code)
        if df.empty:
            print("  ğŸ“­ ê²Œì‹œê¸€ ì—†ìŒ â€” ê±´ë„ˆëœ€")
            continue

        original_count = len(df)
        df['ê°ì„±'] = batch_sentiment_analysis(df['ì œëª©'].tolist())

        # ì¤‘ë¦½ ì œì™¸
        df = df[df['ê°ì„±'].isin([1, -1])]
        remaining_count = len(df)

        print(f"  ğŸ“Š ì›ë³¸: {original_count}ê°œ | ìµœì¢…: {remaining_count}ê°œ")
        if df.empty:
            print("  âšª ë‚¨ì€ ë°ì´í„° ì—†ìŒ â€” ê±´ë„ˆëœ€")
            continue

        dist = df['ê°ì„±'].value_counts(normalize=True)
        sentiment_result = {
            "stock_code": code,
            "stock_name": name,
            "updated_at": datetime.utcnow().isoformat() + "Z",
            "positive": round(dist.get(1, 0), 2),
            "negative": round(dist.get(-1, 0), 2),
            "top_keywords": ', '.join(extract_top_keywords(df['ì œëª©'].tolist()))
        }
        results.append(sentiment_result)

    # JSON ì €ì¥
    os.makedirs("result_json", exist_ok=True)
    json_filename = f"result_json/kospi200_sentiment_{today_str}.json"
    with open(json_filename, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    print(f"\nâœ… ì „ì²´ ì¢…ëª© ë¶„ì„ ì™„ë£Œ. JSON ì €ì¥ ì™„ë£Œ: {json_filename}")

if __name__ == "__main__":
    main(max_stocks=3)  # í…ŒìŠ¤íŠ¸ ì‹œ ì›í•˜ëŠ” ì¢…ëª© ìˆ˜ ì¡°ì ˆ
