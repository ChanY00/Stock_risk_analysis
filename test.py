import pandas as pd
import numpy as np
from sklearn.model_selection import KFold
from sklearn.metrics import accuracy_score, f1_score, classification_report
from gemini_sentiment import batch_sentiment_analysis

# ===================== ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸° =====================
def load_test_data(file_path):
    df = pd.read_excel(file_path)
    df = df[['Sentence', 'Emotion']].dropna()
    texts = df['Sentence'].astype(str).tolist()
    labels = df['Emotion'].astype(int).tolist()
    return texts, labels

# ===================== ì¤‘ë¦½ ì œê±° (ì´ì§„ ë¶„ë¥˜ìš©) =====================
def binary_filter(texts, labels):
    filtered_texts, filtered_labels = [], []
    for text, label in zip(texts, labels):
        if label != 0:  # ì¤‘ë¦½ ì œê±°
            filtered_texts.append(text)
            filtered_labels.append(label)
    return filtered_texts, filtered_labels

# ===================== ë‹¨ì¼ í‰ê°€ í•¨ìˆ˜ =====================
def evaluate_sentiment_model(file_path, batch_size=5, max_workers=5, sample_fraction=0.1):
    texts, true_labels = load_test_data(file_path)
    texts, true_labels = binary_filter(texts, true_labels)
    total = len(texts)
    print(f"ì´ {total}ê°œì˜ ê¸ì •/ë¶€ì • í…ŒìŠ¤íŠ¸ ìƒ˜í”Œì„ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")

    sample_size = int(total * sample_fraction)
    texts = texts[:sample_size]
    true_labels = true_labels[:sample_size]
    print(f"{int(sample_fraction*100)}% ìƒ˜í”Œ ({sample_size}ê°œ)ë¡œ í‰ê°€í•©ë‹ˆë‹¤.")

    predicted_labels = batch_sentiment_analysis(texts, batch_size=batch_size, max_workers=max_workers)

    # ì¤‘ë¦½(None) ì˜ˆì¸¡ ì œê±°
    filtered_preds, filtered_labels = [], []
    for pred, label in zip(predicted_labels, true_labels):
        if pred is not None:
            filtered_preds.append(pred)
            filtered_labels.append(label)

    acc = accuracy_score(filtered_labels, filtered_preds)
    f1 = f1_score(filtered_labels, filtered_preds, average='weighted')
    print(f"\nğŸ” ì „ì²´ ì •í™•ë„: {acc * 100:.2f}%")
    print(f"ğŸ” ì „ì²´ F1 Score (ê°€ì¤‘ í‰ê· ): {f1:.2f}\n")

    print("ğŸ” ê¸ì •/ë¶€ì • í´ë˜ìŠ¤ë³„ í‰ê°€:")
    print(classification_report(filtered_labels, filtered_preds, digits=3))

    return filtered_preds, filtered_labels

# ===================== K-Fold êµì°¨ê²€ì¦ í‰ê°€ =====================
def evaluate_cross_validation(texts, labels, n_splits=5, batch_size=5, max_workers=5):
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    acc_list = []
    f1_list = []

    fold = 1
    for train_idx, test_idx in kf.split(texts):
        print(f"\nğŸ“ Fold {fold} í‰ê°€ ì¤‘...")
        X_test = [texts[i] for i in test_idx]
        y_test = [labels[i] for i in test_idx]

        y_pred = batch_sentiment_analysis(X_test, batch_size=batch_size, max_workers=max_workers)

        # ì¤‘ë¦½ ì œê±°
        filtered_preds, filtered_labels = [], []
        for pred, label in zip(y_pred, y_test):
            if pred is not None:
                filtered_preds.append(pred)
                filtered_labels.append(label)

        acc = accuracy_score(filtered_labels, filtered_preds)
        f1 = f1_score(filtered_labels, filtered_preds, average='weighted')

        print(f"  ì •í™•ë„: {acc * 100:.2f}%")
        print(f"  F1 Score: {f1:.2f}")
        acc_list.append(acc)
        f1_list.append(f1)

        fold += 1

    print("\nâœ… êµì°¨ê²€ì¦ í‰ê·  ê²°ê³¼:")
    print(f"ğŸ”¹ í‰ê·  ì •í™•ë„: {np.mean(acc_list) * 100:.2f}%")
    print(f"ğŸ”¹ í‰ê·  F1 Score: {np.mean(f1_list):.2f}")

# ===================== ì‹¤í–‰ ì˜ˆì‹œ =====================
if __name__ == "__main__":
    test_file_path = r"C:\Users\dnjsr\Desktop\ì§„ì§œ ì¡¸ì‘\test_dataset\test_data.xlsx"
    batch_size = 5
    max_workers = 5

    mode = "single"  # "single" ë˜ëŠ” "cross_validation"

    if mode == "single":
        evaluate_sentiment_model(
            test_file_path,
            batch_size=batch_size,
            max_workers=max_workers,
            sample_fraction=1.0
        )
    elif mode == "cross_validation":
        texts, labels = load_test_data(test_file_path)
        texts, labels = binary_filter(texts, labels)
        print(f"ì´ {len(texts)}ê°œì˜ ê¸ì •/ë¶€ì • ìƒ˜í”Œ ë¡œë“œë¨. 5-Fold êµì°¨ê²€ì¦ ì‹œì‘.")
        evaluate_cross_validation(
            texts, labels,
            n_splits=5,
            batch_size=batch_size,
            max_workers=max_workers
        )
